"use strict";(function(){const t={cache:!0};t.doc={id:"id",field:["title","content"],store:["title","href","section"]};const e=FlexSearch.create("balance",t);window.bookSearchIndex=e,e.add({id:0,href:"/posts/aoc2023-day06/",title:"Advent of code 2023 - Day 6: Wait For It",section:"Posts",content:`This year I try to record my attempt at solving the Advent of Code 2023 riddles. This is Day 6 - see https:adventofcode.com/2023/day/6
Part 1 # Lets first read the task: You manage to sign up as a competitor in the boat races just in time. The organizer explains that it&rsquo;s not really a traditional race - instead, you will get a fixed amount of time during which your boat has to travel as far as it can, and you win if your boat goes the farthest.
As part of signing up, you get a sheet of paper (your puzzle input) that lists the time allowed for each race and also the best distance ever recorded in that race. To guarantee you win the grand prize, you need to make sure you go farther in each race than the current record holder.
The organizer brings you over to the area where the boat races are held. The boats are much smaller than you expected - they&rsquo;re actually toy boats, each with a big button on top. Holding down the button charges the boat, and releasing the button allows the boat to move. Boats move faster if their button was held longer, but time spent holding the button counts against the total race time. You can only hold the button at the start of the race, and boats don&rsquo;t move until the button is released.
For example:
Time: 7 15 30 Distance: 9 40 200 This document describes three races:
The first race lasts 7 milliseconds. The record distance in this race is 9 millimeters. The second race lasts 15 milliseconds. The record distance in this race is 40 millimeters. The third race lasts 30 milliseconds. The record distance in this race is 200 millimeters. Your toy boat has a starting speed of zero millimeters per millisecond. For each whole millisecond you spend at the beginning of the race holding down the button, the boat&rsquo;s speed increases by one millimeter per millisecond.
So, because the first race lasts 7 milliseconds, you only have a few options:
Don&rsquo;t hold the button at all (that is, hold it for 0 milliseconds) at the start of the race. The boat won&rsquo;t move; it will have traveled 0 millimeters by the end of the race. Hold the button for 1 millisecond at the start of the race. Then, the boat will travel at a speed of 1 millimeter per millisecond for 6 milliseconds, reaching a total distance traveled of 6 millimeters. Hold the button for 2 milliseconds, giving the boat a speed of 2 millimeters per millisecond. It will then get 5 milliseconds to move, reaching a total distance of 10 millimeters. Hold the button for 3 milliseconds. After its remaining 4 milliseconds of travel time, the boat will have gone 12 millimeters. Hold the button for 4 milliseconds. After its remaining 3 milliseconds of travel time, the boat will have gone 12 millimeters. Hold the button for 5 milliseconds, causing the boat to travel a total of 10 millimeters. Hold the button for 6 milliseconds, causing the boat to travel a total of 6 millimeters. Hold the button for 7 milliseconds. That&rsquo;s the entire duration of the race. You never let go of the button. The boat can&rsquo;t move until you let go of the button. Please make sure you let go of the button so the boat gets to move. 0 millimeters. Since the current record for this race is 9 millimeters, there are actually 4 different ways you could win: you could hold the button for 2, 3, 4, or 5 milliseconds at the start of the race.
In the second race, you could hold the button for at least 4 milliseconds and at most 11 milliseconds and beat the record, a total of 8 different ways to win.
In the third race, you could hold the button for at least 11 milliseconds and no more than 19 milliseconds and still beat the record, a total of 9 ways you could win.
To see how much margin of error you have, determine the number of ways you can beat the record in each race; in this example, if you multiply these values together, you get 288 (4 * 8 * 9).
Determine the number of ways you could beat the record in each race. What do you get if you multiply these numbers together?
The solution for this problem is shorter than the task description!
As always - let&rsquo;s load the data. Note: we use the delim_whitesspace argument instead of sep=' ' to separate values by spaces of any length.
import pandas as pd import numpy as np race = pd.read_table(&#39;data/2023-12-06-1-aoc.txt&#39;, delim_whitespace=True, header=None, index_col=0) race.index = [&#39;time&#39;, &#39;distance&#39;] race 1 2 3 4 time 51 92 68 90 distance 222 2031 1126 1225 The we use Python list comprehensions to quickly calculate all distances for the range of the time value (and keep only the winning distances). Then we get the respective lengths and compute the product.
def get_distance(time, distance): return [t * (time - t) for t in range(1, time + 1) if (t * (time - t)) &gt; distance] race.loc[&#39;nwins&#39;, :] = [len(get_distance(int(r.time), int(r.distance))) for c, r in race.items()] nwins_prod = np.prod(race.loc[&#39;nwins&#39;, :].values, dtype=int) display(race) print(f&#39;The product of our nwins is {nwins_prod}&#39;) 1 2 3 4 time 51.0 92.0 68.0 90.0 distance 222.0 2031.0 1126.0 1225.0 nwins 42.0 19.0 11.0 57.0 The product of our nwins is 500346 Part 2 # Lets first read the task: As the race is about to start, you realize the piece of paper with race times and record distances you got earlier actually just has very bad kerning. There&rsquo;s really only one race - ignore the spaces between the numbers on each line.
So, the example from before:
Time: 7 15 30 Distance: 9 40 200 &hellip;now instead means this:
Time: 71530 Distance: 940200 Now, you have to figure out how many ways there are to win this single race. In this example, the race lasts for 71530 milliseconds and the record distance you need to beat is 940200 millimeters. You could hold the button anywhere from 14 to 71516 milliseconds and beat the record, a total of 71503 ways!
How many ways can you beat the record in this one much longer race?
For this riddle we can take the same approach as for Part 1. The cell took 18s to evaluate on a consumer laptop from 2015 - no fancy workarounds needed :)
racetime = int(&#39;&#39;.join(str(r) for r in race.loc[&#39;time&#39;, :4].astype(int))) racedist = int(&#39;&#39;.join(str(r) for r in race.loc[&#39;distance&#39;, :4].astype(int))) racewins = len(get_distance(racetime, racedist)) race[5] = [racetime, racedist, racewins] race 1 2 3 4 5 time 51.0 92.0 68.0 90.0 51926890 distance 222.0 2031.0 1126.0 1225.0 222203111261225 nwins 42.0 19.0 11.0 57.0 42515755 `}),e.add({id:1,href:"/docs/notes/poetry/",title:"Poetry",section:"Notes",content:` Lǎozǐ # I am partial to the translation of Derek Lin
Dàodéjīng - Chapter 11 (The use of what has no substantive existence) [&hellip;]
Mix clay
to create a container
In its emptiness, there is
the function of a container
[&hellip;]
Therefore,
that which exists is used to create benefit
That which is empty is used to create functionality
Dàodéjīng - Chapter 15 (The exhibition of the qualities of the Dao) The Tao masters of antiquity
Subtle wonders through mystery
Depths that cannot be discerned
Because one cannot discern them
Therefore one is forced to describe the appearance
Hesitant,
like crossing a wintry river
Cautious,
like fearing four neighbors
Solemn,
like a guest
Loose,
like ice about to melt
Genuine,
like plain wood
Open,
like a valley
Opaque,
like muddy water
Who can be muddled yet desist
In stillness gradually become clear?
Who can be serene yet persist
In motion gradually come alive?
One who holds this &lt;i&gt;Tao&lt;/i&gt; does not wish to be overfilled
Because one is not overfilled
Therefore one can preserve and not create anew
Dàodéjīng - Chapter 20 (Being different from ordinary people) Cease learning, no more worries
Respectful response and scornful response
How much is the difference?
Goodness and evil
How much do they differ?
What the people fear,
I cannot be unafraid
So desolate! How limitless it is!
The people are excited
As if enjoying a great feast
As if climbing up to the terrace in spring
I alone am quiet and uninvolved
Like an infant
not yet smiling
So weary,
like having no place to return
The people all have surplus
While I alone seem lacking
I have the heart of a fool indeed -
so ignorant!
Ordinary people are bright
I alone am muddled
Ordinary people are scrutinizing
I alone am obtuse
So tranquil, like the ocean
So moving, as if without limits
The people all have goals
And I alone am stubborn and lowly
I alone am different from them
And value the nourishing mother
`}),e.add({id:2,href:"/docs/projects/",title:"Projects",section:"Docs",content:` Current projects # I am a believer in the principles of Open Science, Open Data and Open Source. Thus, I am currently working on a reproducible way of conducting my research on simulation of Fluorescence Correlation Spectroscopy (FCS) measurements and correcting artifacts using neural networks, such as Convolutional Neural Nets (CNNs). I do not have my workflow fixed yet, but to have an insight in my current approach - and with the principles of Open-notebook science in mind:
Fluotracify - doctoral research project done in a reproducible way
Description: In a current project, we apply Deep Learning techniques on Fluorescence Correlation Spectroscopy (FCS) data to correct a variety of hardware- and sample-related artifacts, such as photobleaching, contamination from additional slow moving particles, or sudden drops in intensity because of detector anomalies.
Conference talks # Seltmann A, Eggeling C, Waithe D. Automated, User-independent Correction of Artifacts in Fluorescence Correlation Spectroscopy Measurements using Convolutional Neural Networks. Quantitative BioImaging Conference (QBI); 2020 Jan 6-9; Oxford, UK `}),e.add({id:3,href:"/posts/aoc2023-day05/",title:"Advent of code 2023 - Day 5: If You Give A Seed A Fertilizer",section:"Posts",content:`This year I try to record my attempt at solving the Advent of Code 2023 riddles. This is Day 5 - see https:adventofcode.com/2023/day/5
Update [2023-12-31 So]:
subsitute get_generator() (own implementation) with range() (Python inbuilt) improve grid search so that it goes through all location ranges, still starting with the lowest range Part 1 # Lets first read the task:
The almanac (your puzzle input) lists all of the seeds that need to be planted. It also lists what type of soil to use with each kind of seed, what type of fertilizer to use with each kind of soil, what type of water to use with each kind of fertilizer, and so on. Every type of seed, soil, fertilizer and so on is identified with a number, but numbers are reused by each category - that is, soil 123 and fertilizer 123 aren&rsquo;t necessarily related to each other.
For example:
seeds: 79 14 55 13 seed-to-soil map: 50 98 2 52 50 48 soil-to-fertilizer map: 0 15 37 37 52 2 39 0 15 fertilizer-to-water map: 49 53 8 0 11 42 42 0 7 57 7 4 water-to-light map: 88 18 7 18 25 70 light-to-temperature map: 45 77 23 81 45 19 68 64 13 temperature-to-humidity map: 0 69 1 1 0 69 humidity-to-location map: 60 56 37 56 93 4 The almanac starts by listing which seeds need to be planted: seeds 79, 14, 55, and 13.
The rest of the almanac contains a list of maps which describe how to convert numbers from a source category into numbers in a destination category. That is, the section that starts with seed-to-soil map: describes how to convert a seed number (the source) to a soil number (the destination). This lets the gardener and his team know which soil to use with which seeds, which water to use with which fertilizer, and so on.
Rather than list every source number and its corresponding destination number one by one, the maps describe entire ranges of numbers that can be converted. Each line within a map contains three numbers: the destination range start, the source range start, and the range length.
Consider again the example seed-to-soil map:
50 98 2 52 50 48
The first line has a destination range start of 50, a source range start of 98, and a range length of 2. This line means that the source range starts at 98 and contains two values: 98 and 99. The destination range is the same length, but it starts at 50, so its two values are 50 and 51. With this information, you know that seed number 98 corresponds to soil number 50 and that seed number 99 corresponds to soil number 51. o The second line means that the source range starts at 50 and contains 48 values: 50, 51, &hellip;, 96, 97. This corresponds to a destination range starting at 52 and also containing 48 values: 52, 53, &hellip;, 98, 99. So, seed number 53 corresponds to soil number 55.
Any source numbers that aren&rsquo;t mapped correspond to the same destination number. So, seed number 10 corresponds to soil number 10.
So, the entire list of seed numbers and their corresponding soil numbers looks like this:
seed soil 0 0 1 1 ... ... 48 48 49 49 50 52 51 53 ... ... 96 98 97 99 98 50 99 51 With this map, you can look up the soil number required for each initial seed number:
Seed number 79 corresponds to soil number 81. Seed number 14 corresponds to soil number 14. Seed number 55 corresponds to soil number 57. Seed number 13 corresponds to soil number 13. The gardener and his team want to get started as soon as possible, so they&rsquo;d like to know the closest location that needs a seed. Using these maps, find the lowest location number that corresponds to any of the initial seeds. To do this, you&rsquo;ll need to convert each seed number through other categories until you can find its corresponding location number. In this example, the corresponding types are:
Seed 79, soil 81, fertilizer 81, water 81, light 74, temperature 78, humidity 78, location 82. Seed 14, soil 14, fertilizer 53, water 49, light 42, temperature 42, humidity 43, location 43. Seed 55, soil 57, fertilizer 57, water 53, light 46, temperature 82, humidity 82, location 86. Seed 13, soil 13, fertilizer 52, water 41, light 34, temperature 34, humidity 35, location 35. So, the lowest location number in this example is 35.
What is the lowest location number that corresponds to any of the initial seed numbers?
Wow, this task is a mouthful&hellip;
Let&rsquo;s start slowly and load the data. Our input text document contains several maps, which are clearly separated and have a title (seed-to-soil map etc). So we can tell pandas where each map starts and give each map a dataframe. I got the values for the skiprows and nrows argument by looking at the input file and&hellip; counting :)
import pandas as pd import sys seeds = pd.read_table(&#39;data/2023-12-05-1-aoc.txt&#39;, nrows=1, sep=&#39; &#39;, header=None, index_col=0) seeds = seeds.values.flatten() map_opt = {&#39;filepath_or_buffer&#39;: &#39;data/2023-12-05-1-aoc.txt&#39;, &#39;header&#39;: None, &#39;sep&#39;: &#39; &#39;, &#39;dtype&#39;: &#39;Int64&#39;, &#39;names&#39;: [&#39;dest_start&#39;, &#39;src_start&#39;, &#39;range&#39;]} seed_soil = pd.read_table(skiprows=3, nrows=23, **map_opt) soil_fert = pd.read_table(skiprows=28, nrows=9, **map_opt) fert_water = pd.read_table(skiprows=39, nrows=20, **map_opt) water_light = pd.read_table(skiprows=61, nrows=40, **map_opt) light_temp = pd.read_table(skiprows=103, nrows=36, **map_opt) temp_humi = pd.read_table(skiprows=141, nrows=35, **map_opt) humi_loc = pd.read_table(skiprows=178, nrows=26, **map_opt) maps = (seed_soil, soil_fert, fert_water, water_light, light_temp, temp_humi, humi_loc) print(&#39;seeds are just a numpy array:&#39;) display(seeds) print(&#39;The &#34;humidity-to-location&#34; map as an example:&#39;) humi_loc seeds are just a numpy array: array([3169137700, 271717609, 3522125441, 23376095, 1233948799, 811833837, 280549587, 703867355, 166086528, 44766996, 2326968141, 69162222, 2698492851, 14603069, 2755327667, 348999531, 2600461189, 92332846, 1054656969, 169099767]) The &#34;humidity-to-location&#34; map as an example: My first attempt was to actually construct ranges like in the example above, mapping out all possible sources and destinations. Python quickly informed me that even constructing one pandas.Series with int64 values mapping seeds to soil would cost 64GB memory - not the best solution.
So we take a different approach. For convenience, let&rsquo;s add a src_end and a dest_end column to our maps:
for df in maps: df[&#39;src_end&#39;] = df.loc[:, &#39;src_start&#39;] + df.loc[:, &#39;range&#39;] df[&#39;dest_end&#39;] = df.loc[:, &#39;dest_start&#39;] + df.loc[:, &#39;range&#39;] print(&#39;Again the &#34;humidity-to-location&#34; map as an example:&#39;) humi_loc Again the &#34;humidity-to-location&#34; map as an example: Now we actually compute the mapping. For each seed, we go through all mappings and in each mapping we go through each row. We find the row which contains the mapping and exctract the destination, which is the source for the next map until we reach the last map which gives us the locations.
Approach 1: df.itertuples() is a convenient way to step through a pandas.DataFrame in this example. It is faster than df.iterrows() and returns the row as a NamedTuple - nice!
Approach 2: I actually wondered if it would be faster to get all maps in one pd.DataFrame and then iterate through the mappings. To test this let&rsquo;s construct a new DataFrame maps_df which contains all maps. Since the maps have different lengths it is important to cast the datatype to Int64, which is short for pd.Int64Dtype() and keeps values as integers, even if NA values are in the same column.
Approach 3: A third alternative I tested (not shown here) was to check if a value is in a Python range with the in operator as in: if 3 in range(5):... . This was way too slow.
# mapping version 1 def get_location(seed): current = seed for df in maps: current_map = [row for row in df.itertuples() if ((current &gt; row.src_start) and (current &lt; row.src_end))] if len(current_map) == 0: pass elif len(current_map) == 1: current = (current_map[0].dest_start + (current - current_map[0].src_start)) else: raise ValueError(&#39;This should not happen!&#39;) return current # mapping version 2 - around 10 times slower # you need to rename the maps_df columns so that they have a unique id # e.g. &#39;src_start_1&#39;, &#39;src_start_2&#39; etc # maps_df = pd.concat(maps, axis=&#39;columns&#39;) # def get_dest(i, src): # return (maps_df[(src &gt; maps_df.loc[:, f&#39;src_start_{i}&#39;]) &amp; # (src &lt; maps_df.loc[:, f&#39;src_end_{i}&#39;])] # .loc[:, f&#39;dest_start_{i}&#39;] # .iloc[0]) # def get_location2(seed): # dest = seed # i = 1 # while i &lt; 7: # dest = get_dest(i, dest) # i += 1 # return dest %timeit get_location(seeds[0]) 7.89 ms ± 1.37 ms per loop (mean ± std. dev. of 7 runs, 100 loops each) Now let&rsquo;s get a list of locations:
locations = [get_location(s) for s in seeds] locations 2493982655 3209845376 3992357533 4163131463 4104485616 1952252479 3218677354 388071289 2181441450 2594336315 4049507670 2084517144 3119633635 428978312 3518771991 3704555655 953918455 2107687768 3448046330 2184454689 Lastly, just get the minimum of all location values.
Reveal solution! min(locations) 388071289 Part 2 # Everyone will starve if you only plant such a small number of seeds. Re-reading the almanac, it looks like the seeds: line actually describes ranges of seed numbers.
The values on the initial seeds: line come in pairs. Within each pair, the first value is the start of the range and the second value is the length of the range. So, in the first line of the example above:
seeds: 79 14 55 13
This line describes two ranges of seed numbers to be planted in the garden. The first range starts with seed number 79 and contains 14 values: 79, 80, &hellip;, 91, 92. The second range starts with seed number 55 and contains 13 values: 55, 56, &hellip;, 66, 67.
Now, rather than considering four seed numbers, you need to consider a total of 27 seed numbers.
In the above example, the lowest location number can be obtained from seed number 82, which corresponds to soil 84, fertilizer 84, water 84, light 77, temperature 45, humidity 46, and location 46. So, the lowest location number is 46.
Consider all of the initial seed numbers listed in the ranges on the first line of the almanac. What is the lowest location number that corresponds to any of the initial seed numbers?
Let&rsquo;s first construct a dataframe containing the range of seeds:
seeds_df = pd.DataFrame({&#39;start&#39;: seeds[::2], &#39;range&#39;: seeds[1::2], &#39;end&#39;: seeds[::2] + seeds[1::2]}) print(f&#39;There are {sum(seeds_df.loc[:, &#34;range&#34;]):_} seeds in total&#39;) seeds_df There are 2_549_759_327 seeds in total Now - I really needed some time to finally realize, that going through all seed values is really unfeasable. So how do we deal with this problem?
In the end we need the lowest location number - thus our approach is to take the humi_loc map, start with the lowest location number and go up and get the corresponding seed values. The location of the first seed value which is inside seeds_df is our solution.
So first we rebuild the get_location function to a get_seed function (we reverse the maps tuple with maps[::-1] and switch src and dest).
def get_seed(location): current = location for df in maps[::-1]: current_map = [row for row in df.itertuples() if ((current &gt;= row.dest_start) and (current &lt; row.dest_end))] if len(current_map) == 0: pass elif len(current_map) == 1: current = (current_map[0].src_start + (current - current_map[0].dest_start)) else: raise ValueError(&#39;This should not happen!&#39;) return current Since the Python 3 range function does not store it&rsquo;s contents in memory (similar to a generator), it is well suited to go through these large ranges.
Lastly, we deal with the sheer amount of possible values by performing a grid search. First, we check every millionth location. After the first match, we stop this search and check the last million locations before the match with a finer grid and so on. The last grid is just 1, so we find our lowest location.
Update: We order our locations from smallest to largest with sort_values and go through them - but the search stops after the first match, since that will be our lowest location.
def grid_search(start: int, end: int, grid: list[int]): success = False for g in grid: print(f&#39;Start search with grid={g}&#39;) for l in range(start, end, g): current = get_seed(l) if any((current &gt;= seeds_df.loc[:, &#39;start&#39;]) &amp; (current &lt; seeds_df.loc[:, &#39;end&#39;])): print(f&#39;location {l} is the lowest which contains one of the given seeds ({current})&#39;) start = l - g end = l success = True break return success for row in humi_loc.sort_values(&#39;dest_start&#39;).itertuples(): success = grid_search(start=row.dest_start, end=row.dest_end, grid=[1_000_000, 100_000, 1000, 1]) if success: print(&#39;Finished search&#39;) break Start search with grid=1000000 location 85000000 is the lowest which contains one of the given seeds (2605777210) Start search with grid=100000 location 84300000 is the lowest which contains one of the given seeds (2605077210) Start search with grid=1000 location 84207000 is the lowest which contains one of the given seeds (2604984210) Start search with grid=1 location 84206669 is the lowest which contains one of the given seeds (2604983879) Finished search `}),e.add({id:4,href:"/posts/aoc2023-day04/",title:"Advent of code 2023 - Day 4: Scratchcards",section:"Posts",content:`This year I try to record my attempt at solving the Advent of Code 2023 riddles. This is Day 4 - see https:adventofcode.com/2023/day/4
Part 1 # Lets first read the task:
The Elf leads you over to the pile of colorful cards. There, you discover dozens of scratchcards, all with their opaque covering already scratched off. Picking one up, it looks like each card has two lists of numbers separated by a vertical bar (|): a list of winning numbers and then a list of numbers you have. You organize the information into a table (your puzzle input).
As far as the Elf has been able to figure out, you have to figure out which of the numbers you have appear in the list of winning numbers. The first match makes the card worth one point and each match after the first doubles the point value of that card.
For example:
Card 1: 41 48 83 86 17 | 83 86 6 31 17 9 48 53 Card 2: 13 32 20 16 61 | 61 30 68 82 17 32 24 19 Card 3: 1 21 53 59 44 | 69 82 63 72 16 21 14 1 Card 4: 41 92 73 84 69 | 59 84 76 51 58 5 54 83 Card 5: 87 83 26 28 32 | 88 30 70 12 93 22 82 36 Card 6: 31 18 13 56 72 | 74 77 10 23 35 67 36 11 In the above example, card 1 has five winning numbers (41, 48, 83, 86, and 17) and eight numbers you have (83, 86, 6, 31, 17, 9, 48, and 53). Of the numbers you have, four of them (48, 83, 17, and 86) are winning numbers! That means card 1 is worth 8 points (1 for the first match, then doubled three times for each of the three matches after the first).
Card 2 has two winning numbers (32 and 61), so it is worth 2 points. Card 3 has two winning numbers (1 and 21), so it is worth 2 points. Card 4 has one winning number (84), so it is worth 1 point. Card 5 has no winning numbers, so it is worth no points. Card 6 has no winning numbers, so it is worth no points. So, in this example, the Elf&rsquo;s pile of scratchcards is worth 13 points.
Take a seat in the large pile of colorful cards. How many points are they worth in total?
Loading this data is very similar to Day 2 - so let&rsquo;s load the data as we did there. Our goal is to get win and yours columns holding the respective digits which we want to compare. We find the numbers with one or more digits using the regex \\d+. And we want them to be in sets (not lists), as we can logically compare sets in Python.
import pandas as pd import re txt = pd.read_table(&#39;data/2023-12-04-1-aoc.txt&#39;, names=[&#39;win&#39;]) txt[&#39;id&#39;] = txt.loc[:, &#39;win&#39;].str.split(&#39;:&#39;).apply( lambda x: int(x[0].strip(&#39;Card &#39;))) txt[&#39;win&#39;] = (txt.loc[:, &#39;win&#39;] .str.split(&#39;:&#39;).apply(lambda x: x[1])) txt[&#39;yours&#39;] = (txt.loc[:, &#39;win&#39;] .str.split(&#39;|&#39;) .apply(lambda x: x[1]) # get a list of only the numbers / digits .apply(lambda x: re.findall(r&#39;\\d+&#39;, x)) # convert the list of strings to a set of integers .apply(lambda x: set([int(i) for i in x]))) txt[&#39;win&#39;] = (txt.loc[:, &#39;win&#39;] .str.split(&#39;|&#39;) .apply(lambda x: x[0]) .apply(lambda x: re.findall(r&#39;\\d+&#39;, x)) .apply(lambda x: set([int(i) for i in x]))) txt Now, we get the logical conjunction of win and yours, these are our winning numbers. Then, the number of wins is converted to points - for all number of wins bigger than 1, we can get the points by 2**(n_wins-1).
txt[&#39;n_wins&#39;] = txt.apply( lambda row: len(row.loc[&#39;win&#39;] &amp; row.loc[&#39;yours&#39;]), axis=1) txt[&#39;points&#39;] = txt.loc[:, &#39;n_wins&#39;].apply( lambda x: 2**(x-1) if x &gt; 1 else x) txt.loc[:, [&#39;win&#39;, &#39;n_wins&#39;, &#39;points&#39;]] Then, we just sum up:
Reveal solution! sum(txt.loc[:, &#39;points&#39;]) 25004 Part 2 # There&rsquo;s no such thing as &ldquo;points&rdquo;. Instead, scratchcards only cause you to win more scratchcards equal to the number of winning numbers you have.
Specifically, you win copies of the scratchcards below the winning card equal to the number of matches. So, if card 10 were to have 5 matching numbers, you would win one copy each of cards 11, 12, 13, 14, and 15.
Copies of scratchcards are scored like normal scratchcards and have the same card number as the card they copied. So, if you win a copy of card 10 and it has 5 matching numbers, it would then win a copy of the same cards that the original card 10 won: cards 11, 12, 13, 14, and 15. This process repeats until none of the copies cause you to win any more cards. (Cards will never make you copy a card past the end of the table.)
This time, the above example goes differently:
Card 1: 41 48 83 86 17 | 83 86 6 31 17 9 48 53 Card 2: 13 32 20 16 61 | 61 30 68 82 17 32 24 19 Card 3: 1 21 53 59 44 | 69 82 63 72 16 21 14 1 Card 4: 41 92 73 84 69 | 59 84 76 51 58 5 54 83 Card 5: 87 83 26 28 32 | 88 30 70 12 93 22 82 36 Card 6: 31 18 13 56 72 | 74 77 10 23 35 67 36 11 Card 1 has four matching numbers, so you win one copy each of the next four cards: cards 2, 3, 4, and 5. Your original card 2 has two matching numbers, so you win one copy each of cards 3 and 4. Your copy of card 2 also wins one copy each of cards 3 and 4. Your four instances of card 3 (one original and three copies) have two matching numbers, so you win four copies each of cards 4 and 5. Your eight instances of card 4 (one original and seven copies) have one matching number, so you win eight copies of card 5. Your fourteen instances of card 5 (one original and thirteen copies) have no matching numbers and win no more cards. Once all of the originals and copies have been processed, you end up with 1 instance of card 1, 2 instances of card 2, 4 instances of card 3, 8 instances of card 4, 14 instances of card 5, and 1 instance of card 6. In total, this example pile of scratchcards causes you to ultimately have 30 scratchcards!
Process all of the original and copied scratchcards until no more scratchcards are won. Including the original set of scratchcards, how many total scratchcards do you end up with?
We will use the n_wins column we created before and go from there. We step through each Game. Each current game gets +1 card. Then, we step through the number of next games depending on our n_wins. Each of these gets added the card number of the current game.
txt[&#39;cards&#39;] = 0 for i, nwin in enumerate(txt.loc[:, &#39;n_wins&#39;]): txt.loc[i, &#39;cards&#39;] += 1 for j in range(1, nwin+1): txt.loc[i+j, &#39;cards&#39;] += txt.loc[i, &#39;cards&#39;] txt.loc[:, [&#39;n_wins&#39;, &#39;cards&#39;]] Now, we just sum the output again:
Reveal solution! sum(txt[&#39;cards&#39;]) 14427616 `}),e.add({id:5,href:"/posts/aoc2023-day03/",title:"Advent of code 2023 - Day 3: Gear Ratios",section:"Posts",content:`This year I try to record my attempt at solving the Advent of Code 2023 riddles. This is Day 3 - see https:adventofcode.com/2023/day/3
Part 1 # Lets first read the task:
The engine schematic (your puzzle input) consists of a visual representation of the engine. There are lots of numbers and symbols you don&rsquo;t really understand, but apparently any number adjacent to a symbol, even diagonally, is a &ldquo;part number&rdquo; and should be included in your sum. (Periods (.) do not count as a symbol.)
Here is an example engine schematic:
467..114.. ...*...... ..35..633. ......#... 617*...... .....+.58. ..592..... ......755. ...$.*.... .664.598.. In this schematic, two numbers are not part numbers because they are not adjacent to a symbol: 114 (top right) and 58 (middle right). Every other number is adjacent to a symbol and so is a part number; their sum is 4361.
Of course, the actual engine schematic is much larger. What is the sum of all of the part numbers in the engine schematic?
Okay, let&rsquo;s first get the input as a numpy character array
import numpy as np import pandas as pd import sys import matplotlib.pyplot as plt from scipy import ndimage as ndi np.set_printoptions(threshold=sys.maxsize) txt = pd.read_table(&#39;data/2023-12-03-1-aoc.txt&#39;, names=[&#39;code&#39;]) arr = np.chararray((txt.size, txt.size), unicode=True) txt[&#39;code&#39;] = txt.loc[:, &#39;code&#39;].apply(lambda x: [i for i in x]) for i, code in enumerate(txt[&#39;code&#39;]): arr[i, :] = code print((arr[:15, :15])) [[&#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39;] [&#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;5&#39; &#39;3&#39; &#39;.&#39; &#39;4&#39;] [&#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;*&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39;] [&#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;7&#39; &#39;2&#39; &#39;6&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39;] [&#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;9&#39; &#39;5&#39;] [&#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;7&#39; &#39;3&#39; &#39;8&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;*&#39; &#39;.&#39;] [&#39;.&#39; &#39;7&#39; &#39;4&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;3&#39; &#39;6&#39; &#39;6&#39;] [&#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;*&#39; &#39;1&#39; &#39;2&#39; &#39;6&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39;] [&#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;3&#39; &#39;3&#39; &#39;1&#39; &#39;/&#39; &#39;.&#39; &#39;.&#39; &#39;9&#39;] [&#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;/&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;*&#39;] [&#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;9&#39; &#39;5&#39; &#39;3&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;3&#39; &#39;5&#39; &#39;5&#39; &#39;.&#39;] [&#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39;] [&#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39;] [&#39;.&#39; &#39;6&#39; &#39;8&#39; &#39;5&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;*&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;7&#39; &#39;0&#39;] [&#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;.&#39; &#39;9&#39; &#39;3&#39; &#39;8&#39; &#39;.&#39; &#39;.&#39; &#39;*&#39;]] Now extract symbols, digits and the empty space. We use the numpy character methods for that. This way, we create a binary mask for all digits and a binary mask for all empty space (.). The symbols are then every character which is neither.
digits = np.char.isdigit(arr) empty = np.char.endswith(arr, &#39;.&#39;) symbols = ~(digits | empty) # just for visualization plt.figure(figsize=(16, 5)) plt.subplot(131, title=&#39;symbols&#39;).matshow(symbols) plt.subplot(132, title=&#39;digits&#39;).matshow(digits) plt.subplot(133, title=&#39;empty&#39;).matshow(empty) plt.show() Now we use the image processing technique of dilation on the symbols mask. So that we get a new mask which covers the surroundings of all symbols. We use this afterwards to check if the digits are near a symbol.
struct = ((1, 1, 1), (1, 1, 1), (1, 1, 1)) dilate = ndi.binary_dilation(symbols, structure=struct) plt.figure(figsize=(10, 6)) plt.subplot(121, title=&#39;symbols&#39;).matshow(symbols[:15, :15]) plt.subplot(122, title=&#39;symbols dilated&#39;).matshow(dilate[:15, :15]) plt.show() Creating this masks as before could be understood as a binary segmentation, as each element in our mask is either True or False. To extract the single digits, we&rsquo;ll convert the binary digits segmentation into a instance segmentation, where each connected segment has an own index.
markers, num_features = ndi.label(digits) plt.figure(figsize=(10, 6)) plt.subplot(121, title=&#39;binary segmentation&#39;).matshow( digits[:15, :15]) plt.subplot(122, title=&#39;instance segmentation&#39;).matshow( markers[:15, :15], cmap=&#39;gnuplot&#39;) plt.show() Now, for each instance, we check if the dilated binary mask overlaps with the instance and if yes, we extract the number.
numbers = [int(&#39;&#39;.join(arr[markers == i])) for i in range(1, num_features+1) if np.any((markers == i) &amp; dilate)] Then, we just sum up:
Reveal solution! sum(numbers) 527364 Part 2 # The missing part wasn&rsquo;t the only issue - one of the gears in the engine is wrong. A gear is any * symbol that is adjacent to exactly two part numbers. Its gear ratio is the result of multiplying those two numbers together.
This time, you need to find the gear ratio of every gear and add them all up so that the engineer can figure out which gear needs to be replaced.
Consider the same engine schematic again:The missing part wasn&rsquo;t the only issue - one of the gears in the engine is wrong. A gear is any * symbol that is adjacent to exactly two part numbers. Its gear ratio is the result of multiplying those two numbers together.
This time, you need to find the gear ratio of every gear and add them all up so that the engineer can figure out which gear needs to be replaced.
Consider the same engine schematic again:
467..114.. ...*...... ..35..633. ......#... 617*...... .....+.58. ..592..... ......755. ...$.*.... .664.598.. In this schematic, there are two gears. The first is in the top left; it has part numbers 467 and 35, so its gear ratio is 16345. The second gear is in the lower right; its gear ratio is 451490. (The * adjacent to 617 is not a gear because it is only adjacent to one part number.) Adding up all of the gear ratios produces 467835.
What is the sum of all of the gear ratios in your engine schematic?
We&rsquo;ll use the same method as before, but this time only extract * and create the instance segmentation before the dilation. Why? Because when we dilate first, we could merge two independent gears into one instance.
gear = np.char.endswith(arr, &#39;*&#39;) gear_markers, gear_num = ndi.label(gear) plt.figure(figsize=(10, 6)) plt.subplot(131, title=&#39;all symbols dilated&#39;).matshow( symbols[:15, :15]) plt.subplot(132, title=&#39;gears&#39;).matshow( gear[:15, :15]) plt.subplot(133, title=&#39;gears instances&#39;).matshow( gear_markers[:15, :15], cmap=&#39;gnuplot&#39;) plt.show() Now, we step through each gear instance, create a mask for that gear, dilate it, and then step through all digits and check if they are in the gear mask. If we get two digits in the end, we multiply them to get the dear ratio and save the ratios to a list.
gear_ratios = [] for i in range(1, gear_num+1): gear_binary = gear_markers == i gear_dil = ndi.binary_dilation(gear_binary, structure=struct) for j in range(1, num_features+1) if np.any((markers == j) &amp; gear_dil)] if len(part_numbers) == 2: gear_ratios.append(part_numbers[0] * part_numbers[1]) Cell In[21], line 7 for j in range(1, num_features+1) ^ IndentationError: unexpected indent Now, we just sum the output again:
Reveal solution! sum(gear_ratios) --------------------------------------------------------------------------- NameError Traceback (most recent call last) Cell In[22], line 1 ----&gt; 1 sum(gear_ratios) NameError: name &#39;gear_ratios&#39; is not defined `}),e.add({id:6,href:"/posts/aoc2023-day02/",title:"Advent of code 2023 - Day 2: Cube Conundrum",section:"Posts",content:`This year I try to record my attempt at solving the Advent of Code 2023 riddles. This is Day 2 - see https:adventofcode.com/2023/day/2
Part 1 # Lets first read the task:
As you walk, the Elf shows you a small bag and some cubes which are either red, green, or blue. Each time you play this game, he will hide a secret number of cubes of each color in the bag, and your goal is to figure out information about the number of cubes.
To get information, once a bag has been loaded with cubes, the Elf will reach into the bag, grab a handful of random cubes, show them to you, and then put them back in the bag. He&rsquo;ll do this a few times per game.
You play several games and record the information from each game (your puzzle input). Each game is listed with its ID number (like the 11 in Game 11: ...) followed by a semicolon-separated list of subsets of cubes that were revealed from the bag (like 3 red, 5 green, 4 blue).
For example, the record of a few games might look like this:
Game 1: 3 blue, 4 red; 1 red, 2 green, 6 blue; 2 green Game 2: 1 blue, 2 green; 3 green, 4 blue, 1 red; 1 green, 1 blue Game 3: 8 green, 6 blue, 20 red; 5 blue, 4 red, 13 green; 5 green, 1 red Game 4: 1 green, 3 red, 6 blue; 3 green, 6 red; 3 green, 15 blue, 14 red Game 5: 6 red, 1 blue, 3 green; 2 blue, 1 red, 2 green In game 1, three sets of cubes are revealed from the bag (and then put back again). The first set is 3 blue cubes and 4 red cubes; the second set is 1 red cube, 2 green cubes, and 6 blue cubes; the third set is only 2 green cubes.
The Elf would first like to know which games would have been possible if the bag contained only 12 red cubes, 13 green cubes, and 14 blue cubes?
In the example above, games 1, 2, and 5 would have been possible if the bag had been loaded with that configuration. However, game 3 would have been impossible because at one point the Elf showed you 20 red cubes at once; similarly, game 4 would also have been impossible because the Elf showed you 15 blue cubes at once. If you add up the IDs of the games that would have been possible, you get 8.
Determine which games would have been possible if the bag had been loaded with only 12 red cubes, 13 green cubes, and 14 blue cubes. What is the sum of the IDs of those games?
Okay, let&rsquo;s load our python kernel in emacs-jupyter and get coding! First of all, let&rsquo;s load the input and split the riddle code by colon : to extract the game id and the rest of the code by semicolon ; to get the number of sets played in each game.
import pandas as pd import re txt = pd.read_table(&#39;data/2023-12-02-1-aoc.txt&#39;, names=[&#39;code&#39;]) txt[&#39;id&#39;] = txt.loc[:, &#39;code&#39;].str.split(&#39;:&#39;).apply( lambda x: int(x[0].strip(&#39;Game &#39;))) txt[&#39;code&#39;] = txt.loc[:, &#39;code&#39;].str.split(&#39;:&#39;).apply(lambda x: x[1]) # txt[&#39;code&#39;] = txt.loc[:, &#39;code&#39;].str.split(&#39;;&#39;) # txt[&#39;nsets&#39;] = txt.loc[:, &#39;code&#39;].apply(lambda x: len(x)) txt code id 0 1 green, 1 blue, 1 red; 1 green, 8 red, 7 blu... 1 1 9 red, 7 green, 3 blue; 15 green, 2 blue, 5 r... 2 2 3 red, 1 blue, 4 green; 6 red, 3 green, 2 blu... 3 3 2 blue, 2 green, 19 red; 3 blue, 11 red, 16 g... 4 4 8 green, 1 red, 12 blue; 10 green, 6 red, 13 ... 5 .. ... ... 95 2 red, 2 green, 1 blue; 1 red, 4 green; 1 green 96 96 4 red, 5 green; 5 blue, 3 red; 8 blue, 2 gree... 97 97 1 blue; 2 green, 1 red; 5 red, 2 green; 4 red... 98 98 6 blue, 5 red, 2 green; 9 red, 1 blue; 2 gree... 99 99 1 blue, 13 green, 14 red; 11 green, 11 blue, ... 100 [100 rows x 2 columns] Now, let&rsquo;s extract the three colors in different columns with regex. We use the lookahead assertion ?= to find the respective colours and only exctract the digits \\d+ coming before. Then we just keep the max imum drawn number of cubes per color, since this is the only information that matters at the moment.
txt[&#39;green&#39;] = txt.loc[:, &#39;code&#39;].apply( lambda code: re.findall(r&#39;\\d+(?=.green)&#39;, code)).apply( lambda list: max([int(i) for i in list])) txt[&#39;red&#39;] = txt.loc[:, &#39;code&#39;].apply( lambda code: re.findall(r&#39;\\d+(?=.red)&#39;, code)).apply( lambda list: max([int(i) for i in list])) txt[&#39;blue&#39;] = txt.loc[:, &#39;code&#39;].apply( lambda code: re.findall(r&#39;\\d+(?=.blue)&#39;, code)).apply( lambda list: max([int(i) for i in list])) txt code id green red blue 0 1 green, 1 blue, 1 red; 1 green, 8 red, 7 blu... 1 2 10 10 1 9 red, 7 green, 3 blue; 15 green, 2 blue, 5 r... 2 15 10 3 2 3 red, 1 blue, 4 green; 6 red, 3 green, 2 blu... 3 4 6 16 3 2 blue, 2 green, 19 red; 3 blue, 11 red, 16 g... 4 16 20 18 4 8 green, 1 red, 12 blue; 10 green, 6 red, 13 ... 5 10 6 14 .. ... ... ... ... ... 95 2 red, 2 green, 1 blue; 1 red, 4 green; 1 green 96 4 2 1 96 4 red, 5 green; 5 blue, 3 red; 8 blue, 2 gree... 97 5 4 8 97 1 blue; 2 green, 1 red; 5 red, 2 green; 4 red... 98 2 5 2 98 6 blue, 5 red, 2 green; 9 red, 1 blue; 2 gree... 99 2 9 11 99 1 blue, 13 green, 14 red; 11 green, 11 blue, ... 100 13 15 11 [100 rows x 5 columns] Lastly, we just filter the DataFrame to only include games where all drawn cubes were below or equal the number of cubes in the game and sum the result!
txt[&#39;id&#39;][(txt[&#39;green&#39;] &lt; 14) &amp; (txt[&#39;red&#39;] &lt; 13) &amp; (txt[&#39;blue&#39;] &lt; 15)].sum() 3035 Part 2 # First, let&rsquo;s get the instruction from the second part:
As you continue your walk, the Elf poses a second question: in each game you played, what is the fewest number of cubes of each color that could have been in the bag to make the game possible?
Again consider the example games from earlier:
Game 1: 3 blue, 4 red; 1 red, 2 green, 6 blue; 2 green Game 2: 1 blue, 2 green; 3 green, 4 blue, 1 red; 1 green, 1 blue Game 3: 8 green, 6 blue, 20 red; 5 blue, 4 red, 13 green; 5 green, 1 red Game 4: 1 green, 3 red, 6 blue; 3 green, 6 red; 3 green, 15 blue, 14 red Game 5: 6 red, 1 blue, 3 green; 2 blue, 1 red, 2 green In game 1, the game could have been played with as few as 4 red, 2 green, and 6 blue cubes. If any color had even one fewer cube, the game would have been impossible. Game 2 could have been played with a minimum of 1 red, 3 green, and 4 blue cubes. Game 3 must have been played with at least 20 red, 13 green, and 6 blue cubes. Game 4 required at least 14 red, 3 green, and 15 blue cubes. Game 5 needed no fewer than 6 red, 3 green, and 2 blue cubes in the bag. The power of a set of cubes is equal to the numbers of red, green, and blue cubes multiplied together. The power of the minimum set of cubes in game 1 is 48. In games 2-5 it was 12, 1560, 630, and 36, respectively. Adding up these five powers produces the sum 2286.
For each game, find the minimum set of cubes that must have been present. What is the sum of the power of these sets?
Luckily, this task is made trivial by the approach we have taken before. We just have to multiply the green, red and blue columns:
txt[&#39;power&#39;] = txt.loc[:, &#39;green&#39;] * txt.loc[:, &#39;blue&#39;] * txt.loc[:, &#39;red&#39;] txt code id green red blue \\ 0 1 green, 1 blue, 1 red; 1 green, 8 red, 7 blu... 1 2 10 10 1 9 red, 7 green, 3 blue; 15 green, 2 blue, 5 r... 2 15 10 3 2 3 red, 1 blue, 4 green; 6 red, 3 green, 2 blu... 3 4 6 16 3 2 blue, 2 green, 19 red; 3 blue, 11 red, 16 g... 4 16 20 18 4 8 green, 1 red, 12 blue; 10 green, 6 red, 13 ... 5 10 6 14 .. ... ... ... ... ... 95 2 red, 2 green, 1 blue; 1 red, 4 green; 1 green 96 4 2 1 96 4 red, 5 green; 5 blue, 3 red; 8 blue, 2 gree... 97 5 4 8 97 1 blue; 2 green, 1 red; 5 red, 2 green; 4 red... 98 2 5 2 98 6 blue, 5 red, 2 green; 9 red, 1 blue; 2 gree... 99 2 9 11 99 1 blue, 13 green, 14 red; 11 green, 11 blue, ... 100 13 15 11 power 0 200 1 450 2 384 3 5760 4 840 .. ... 95 8 96 160 97 20 98 198 99 2145 [100 rows x 6 columns] And for this one, the sum is:
txt[&#39;power&#39;].sum() 66027 `}),e.add({id:7,href:"/posts/aoc2023-day01/",title:"Advent of code 2023 - Day 1: Trebuchet?!",section:"Posts",content:`This year I try to record my attempt at solving the Advent of Code 2023 riddles. This is Day 1 - see https:adventofcode.com/2023/day/1
Part 1 # Our first task is the following:
The newly-improved calibration document consists of lines of text; each line originally contained a specific calibration value that the Elves now need to recover. On each line, the calibration value can be found by combining the first digit and the last digit (in that order) to form a single two-digit number.
For example:
1abc2 pqr3stu8vwx a1b2c3d4e5f treb7uchet In this example, the calibration values of these four lines are 12, 38, 15, and 77. Adding these together produces 142.
Consider your entire calibration document. What is the sum of all of the calibration values?
Lets start jupyter in our shell to start coding!
conda activate tf jupyter lab --no-browser --port=8888 First, load the test document
import pandas as pd import re txt = pd.read_table(&#39;data/2023-12-01-1-aoc.txt&#39;, names=[&#39;code&#39;]) txt code 0 jjfvnnlfivejj1 1 6fourfour 2 ninevbmltwo69 3 pcg91vqrfpxxzzzoneightzt 4 jpprthxgjfive3one1qckhrptpqdc .. ... 995 583sevenhjxlqzjgbzxhkcl5 996 81s 997 2four3threesxxvlfqfive4 998 nine6eightsevenzx9twoxc 999 hmbfjdfnp989mfivefiverpzrjs [1000 rows x 1 columns] Second, extract the digits. I had to wrap my head around regex matching in python first, because I first tried pandas.extract (which only extracts the first match), then pandas.extractall (which extracts all matches but puts them into a multiindex which makes things more difficult in this case). So I settled for the re.findall version, which returns a list. To concatenate the elements in the list, we take use the join function.
txt[&#39;digits&#39;] = txt.loc[:, &#39;code&#39;].apply( lambda x: &#39;&#39;.join(re.findall(r&#39;(\\d+)&#39;, x))) txt code digits 0 jjfvnnlfivejj1 1 1 6fourfour 6 2 ninevbmltwo69 69 3 pcg91vqrfpxxzzzoneightzt 91 4 jpprthxgjfive3one1qckhrptpqdc 31 .. ... ... 995 583sevenhjxlqzjgbzxhkcl5 5835 996 81s 81 997 2four3threesxxvlfqfive4 234 998 nine6eightsevenzx9twoxc 69 999 hmbfjdfnp989mfivefiverpzrjs 989 [1000 rows x 2 columns] Next, combine the first and the last digit and convert the result from string to integer
txt[&#39;calibration&#39;] = txt.loc[:, &#39;digits&#39;].apply( lambda x: int(x[0] + x[-1])) txt code digits calibration 0 jjfvnnlfivejj1 1 11 1 6fourfour 6 66 2 ninevbmltwo69 69 69 3 pcg91vqrfpxxzzzoneightzt 91 91 4 jpprthxgjfive3one1qckhrptpqdc 31 31 .. ... ... ... 995 583sevenhjxlqzjgbzxhkcl5 5835 55 996 81s 81 81 997 2four3threesxxvlfqfive4 234 24 998 nine6eightsevenzx9twoxc 69 69 999 hmbfjdfnp989mfivefiverpzrjs 989 99 [1000 rows x 3 columns] Lastly, get the sum of our calibration numbers
txt.loc[:, &#39;calibration&#39;].sum() 56465 Part 2 # Now follows part two:
Your calculation isn&rsquo;t quite right. It looks like some of the digits are actually spelled out with letters: one, two, three, four, five, six, seven, eight, and nine also count as valid &ldquo;digits&rdquo;.
Equipped with this new information, you now need to find the real first and last digit on each line. For example:
two1nine eightwothree abcone2threexyz xtwone3four 4nineeightseven2 zoneight234 7pqrstsixteen In this example, the calibration values are 29, 83, 13, 24, 42, 14, and 76. Adding these together produces 281.
What is the sum of all of the calibration values?
Okay, let&rsquo;s see if we can update the pattern matching. To deal with potential overlapping values like oneight which contains one as well as eight, I used the regex positive lookahead ?= as described here. Because this enables capturing overlapping values, I used \\d (one digit) instead of \\d+ (one or more digits), otherwise digits might double. Afterwards, just replace the spelled out digits with their numerical value.
# for i, r in enumerate(txt.loc[:, &#39;code&#39;]): # matches = re.findall( # r&#39;(?=(\\d|one|two|three|four|five|six|seven|eight|nine))&#39;, r) # result = &#39;&#39;.join([match for match in matches]) # result = result.replace(&#39;one&#39;, &#39;1&#39;).replace(&#39;two&#39;, &#39;2&#39;).replace( # &#39;three&#39;, &#39;3&#39;).replace(&#39;four&#39;, &#39;4&#39;).replace(&#39;five&#39;, &#39;5&#39;).replace( # &#39;six&#39;, &#39;6&#39;).replace(&#39;seven&#39;, &#39;7&#39;).replace(&#39;eight&#39;, &#39;8&#39;).replace( # &#39;nine&#39;, &#39;9&#39;) # txt.loc[i, &#39;digits2&#39;] = result # txt # a very nice alternative suggested by Tomalak: digits = &#39;\\d one two three four five six seven eight nine&#39;.split() txt[&#39;digits2&#39;] = txt.loc[:, &#39;code&#39;].apply(lambda v: &#39;&#39;.join( str(digits.index(m)) if m in digits else m for m in re.findall(rf&#39;(?=({&#34;|&#34;.join(digits)}))&#39;, v) )) txt code digits calibration digits2 0 jjfvnnlfivejj1 1 11 51 1 6fourfour 6 66 644 2 ninevbmltwo69 69 69 9269 3 pcg91vqrfpxxzzzoneightzt 91 91 9118 4 jpprthxgjfive3one1qckhrptpqdc 31 31 5311 .. ... ... ... ... 995 583sevenhjxlqzjgbzxhkcl5 5835 55 58375 996 81s 81 81 81 997 2four3threesxxvlfqfive4 234 24 243354 998 nine6eightsevenzx9twoxc 69 69 968792 999 hmbfjdfnp989mfivefiverpzrjs 989 99 98955 [1000 rows x 4 columns] Now, construct the calibration value as before&hellip;
txt[&#39;calibration2&#39;] = txt.loc[:, &#39;digits2&#39;].apply(lambda x: int(x[0] + x[-1])) txt code digits calibration digits2 calibration2 0 jjfvnnlfivejj1 1 11 51 51 1 6fourfour 6 66 644 64 2 ninevbmltwo69 69 69 9269 99 3 pcg91vqrfpxxzzzoneightzt 91 91 9118 98 4 jpprthxgjfive3one1qckhrptpqdc 31 31 5311 51 .. ... ... ... ... ... 995 583sevenhjxlqzjgbzxhkcl5 5835 55 58375 55 996 81s 81 81 81 81 997 2four3threesxxvlfqfive4 234 24 243354 24 998 nine6eightsevenzx9twoxc 69 69 968792 92 999 hmbfjdfnp989mfivefiverpzrjs 989 99 98955 95 [1000 rows x 5 columns] &hellip; and get the correct sum!
txt.loc[:, &#39;calibration2&#39;].sum() 55902 `})})()